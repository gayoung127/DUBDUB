"use client";

import React, { useEffect, useRef, useState } from "react";

import { AudioFile, initialTracks, Track } from "@/app/_types/studio";

import H4 from "@/app/_components/H4";

import Timeline from "./Timeline";
import AudioTrackTimeline from "./AudioTrackTimeline";
import AudioTrackHeader from "./AudioTrackHeader";

import VideoTrack from "./VideoTrack";
import { mergeAudioBuffersWithTimeline } from "@/app/_utils/mergeAudioBuffersWithTimeline";
import { audioBufferToMp3 } from "@/app/_utils/audioBufferToMp3";
import { AudioBlockProps } from "./AudioBlock";
import Button from "@/app/_components/Button";
import { resampleAudioBuffer } from "@/app/_utils/resampleAudioBuffer";
import { socket } from "@/app/_utils/socketClient";

const RecordSection = () => {
  const [tracks, setTracks] = useState<Track[]>(initialTracks);
  const audioContextRef = useRef<AudioContext | null>(null);
  const audioBuffersRef = useRef<Map<string, AudioBuffer>>(new Map());

  // 1. íŠ¸ë™ ì„¸ë¡œ ìŠ¤í¬ë¡¤ ë™ê¸°í™”
  const trackListRef = useRef<HTMLDivElement | null>(null);
  const timelineTracksRef = useRef<HTMLDivElement | null>(null);
  useEffect(() => {
    const headerEl = trackListRef.current;
    const timelineEl = timelineTracksRef.current;

    if (!headerEl || !timelineEl) return;

    const syncScroll = (event: WheelEvent) => {
      event.preventDefault();

      headerEl.scrollTop += event.deltaY;
      timelineEl.scrollTop += event.deltaY;
    };

    headerEl.addEventListener("wheel", syncScroll, { passive: false });
    timelineEl.addEventListener("wheel", syncScroll, { passive: false });

    return () => {
      headerEl.removeEventListener("wheel", syncScroll);
      timelineEl.removeEventListener("wheel", syncScroll);
    };
  }, []);

  useEffect(() => {
    console.log("í˜¸ì¶œì°¡í˜¸ì¶œì°¡", tracks);

    if (!audioContextRef.current) {
      audioContextRef.current = new AudioContext();
    }

    const loadAudioFiles = async () => {
      if (!audioContextRef.current) return;
      const context = audioContextRef.current;

      for (const track of tracks) {
        for (const file of track.files) {
          if (!audioBuffersRef.current.has(file.url)) {
            const response = await fetch(file.url);
            const arrayBuffer = await response.arrayBuffer();
            const audioBuffer = await context.decodeAudioData(arrayBuffer);
            audioBuffersRef.current.set(file.url, audioBuffer);
          }
        }
      }
    };

    loadAudioFiles();
  }, [tracks]);

  useEffect(() => {
    console.log("ğŸ“¤ [CLIENT] íŠ¸ë™ ê°œìˆ˜ë¥¼ ì„œë²„ë¡œ ë™ê¸°í™” ìš”ì²­:", initialTracks);
    socket.emit("sync-client-tracks", initialTracks);
  }, []);

  useEffect(() => {
    socket.on("sync-track", (receivedTracks: Track[]) => {
      console.log("ğŸ“¥ [CLIENT] sync-track ìˆ˜ì‹ :", receivedTracks);
      setTracks(receivedTracks);
    });

    return () => {
      socket.off("sync-track");
    };
  }, []);

  // ì„œë²„ì—ì„œ ë°›ì€ ë³€ê²½ ì‚¬í•­ ì ìš©
  useEffect(() => {
    const handleSyncTracks = ({
      trackId,
      updatedFiles,
    }: {
      trackId: number;
      updatedFiles: AudioFile[];
    }) => {
      console.log(`ğŸ“© [CLIENT] sync-track-files ìˆ˜ì‹ :`, {
        trackId,
        updatedFiles,
      });

      setTracks((prevTracks) => {
        return prevTracks.map((track) => {
          if (track.trackId !== trackId) return track;

          const prevFiles = JSON.stringify(track.files);
          const newFiles = JSON.stringify(updatedFiles);

          if (prevFiles !== newFiles) {
            console.log(
              `ğŸ“ [CLIENT] íŠ¸ë™(${trackId}) ì—…ë°ì´íŠ¸ë¨:`,
              updatedFiles,
            );
            return { ...track, files: updatedFiles };
          } else {
            console.log(
              `âš ï¸ [CLIENT] íŠ¸ë™(${trackId}) ë³€ê²½ ì—†ìŒ, ì—…ë°ì´íŠ¸ ìƒëµ`,
            );
            return track;
          }
        });
      });

      console.log(`ğŸ”„ íŠ¸ë™(${trackId})ì˜ files ë™ê¸°í™” ì™„ë£Œ`, updatedFiles);
    };

    console.log("ğŸ›œ [CLIENT] sync-track-files ì´ë²¤íŠ¸ ë¦¬ìŠ¤ë„ˆ ë“±ë¡");
    socket.on("sync-track-files", handleSyncTracks);

    return () => {
      console.log("ğŸ›œ [CLIENT] sync-track-files ì´ë²¤íŠ¸ ë¦¬ìŠ¤ë„ˆ í•´ì œ");
      socket.off("sync-track-files", handleSyncTracks);
    };
  }, []);

  const handleDownloadMp3 = async () => {
    if (!audioContextRef.current) return;

    // âœ… Track[] â†’ AudioBlockProps[] ë³€í™˜
    const audioBlocks: AudioBlockProps[] = tracks.flatMap((track) =>
      track.files.map((file) => ({
        file,
        audioBuffers: audioBuffersRef.current,
        audioContext: audioContextRef.current,
        setTracks,
        timelineRef: { current: null },
        width: "10000px",
        waveColor: "#000",
        blockColor: "#FFF",
      })),
    );

    if (audioBlocks.length === 0) {
      console.error("âŒ ë³‘í•©í•  ì˜¤ë””ì˜¤ ë¸”ë¡ì´ ì—†ìŠµë‹ˆë‹¤.");
      return;
    }

    // âœ… ì˜¤ë””ì˜¤ ë³‘í•©
    const mergedAudioBuffer = mergeAudioBuffersWithTimeline(
      audioContextRef.current,
      audioBlocks,
    );

    if (!mergedAudioBuffer) {
      console.error("âŒ ì˜¤ë””ì˜¤ ë³‘í•© ì‹¤íŒ¨");
      return;
    }

    console.log("âœ… ë³‘í•©ëœ ì˜¤ë””ì˜¤ ë²„í¼ ìƒì„±ë¨:", mergedAudioBuffer);

    // âœ… MP3 ë³€í™˜ í›„ ë‹¤ìš´ë¡œë“œ
    await audioBufferToMp3(mergedAudioBuffer);
  };

  return (
    <section className="flex h-full w-full flex-row items-start justify-start overflow-hidden">
      <div className="flex h-full w-[280px] flex-shrink-0 flex-col items-start justify-start overflow-hidden border border-gray-300 bg-gray-400">
        <div className="">
          <div className="flex h-[60px] w-[280px] flex-shrink-0 flex-row items-center justify-start border-b border-t border-gray-300 bg-gray-400 px-5 py-5">
            <H4 className="border-b-2 border-white-100 font-bold text-white-100">
              ë…¹ìŒ ì„¸ì…˜
            </H4>
          </div>
          <div className="h-full w-full">
            {tracks.map((track) => (
              <AudioTrackHeader
                key={track.trackId}
                trackId={track.trackId}
                recorderId={track.recorderId}
                recorderName={track.recorderName}
                recorderRole={track.recorderRole}
                recorderProfileUrl={track.recorderProfileUrl}
                setTracks={setTracks}
              />
            ))}
          </div>
        </div>
      </div>

      <div className="mb-2 flex h-full w-full flex-col items-start justify-start overflow-x-hidden border border-gray-300 bg-gray-400">
        <div className="scrollbar-horizontal overflow-x-scoll mb-2 h-full w-full overflow-y-hidden">
          <div className="flex h-[60px] w-full flex-grow-0 flex-col items-start justify-end border-l border-r border-t border-gray-300 bg-gray-400">
            <Timeline totalDuration={160} />
          </div>
          <div className="h-full w-full">
            {tracks.map((track) => (
              <AudioTrackTimeline
                key={track.trackId}
                trackId={track.trackId}
                files={track.files}
                totalDuration={160}
                waveColor={track.waveColor}
                blockColor={track.blockColor}
                audioContext={audioContextRef.current}
                audioBuffers={audioBuffersRef.current}
                setTracks={setTracks}
              />
            ))}
          </div>
        </div>
      </div>
    </section>
  );
};

export default RecordSection;
