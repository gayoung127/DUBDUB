import { toast } from "sonner";
import { useParams } from "next/navigation";
import React, { useEffect, useRef, useState } from "react";

import { useMicStore } from "@/app/_store/MicStore";
import { useUserStore } from "@/app/_store/UserStore";
import { useTimeStore } from "@/app/_store/TimeStore";
import { useRecordingStore } from "@/app/_store/RecordingStore";

import { postAsset } from "@/app/_apis/studio";
import { Asset, Track } from "@/app/_types/studio";
import { formatTime } from "@/app/_utils/formatTime";

import H4 from "@/app/_components/H4";
import ShareButton from "./ShareButton";
import StoreButton from "./StoreButton";
import RenderingButton from "./RenderingButton";

import RecordButton from "@/public/images/icons/icon-record.svg";
import PlayButton from "@/public/images/icons/icon-play.svg";
import StopButton from "@/public/images/icons/icon-stop.svg";
import PauseButton from "@/public/images/icons/icon-pause.svg";
import { usePlaySocket } from "@/app/_hooks/usePlaySocket";

interface PlayBarProps {
  videoRef: React.RefObject<VideoElementWithCapturestream | null>;
  videoUrl: string | undefined;
  duration: number;
  setDuration: React.Dispatch<React.SetStateAction<number>>;
  tracks: Track[];
  setTracks: React.Dispatch<React.SetStateAction<Track[]>>;
  assets: Asset[];
}

const PlayBar = ({
  videoRef,
  videoUrl,
  duration,
  setDuration,
  tracks,
  setTracks,
  assets,
}: PlayBarProps) => {
  const { self } = useUserStore();
  const { micStatus } = useMicStore();
  const { time, isPlaying, play, pause, reset } = useTimeStore();
  const {
    isRecording,
    audioContext,
    startRecording,
    stopRecording,
    createAudioFile,
    setMediaRecorder,
    setAudioContext,
    setAnalyser,
  } = useRecordingStore();

  const { sendPlaybackStatus } = usePlaySocket();

  const mediaRecorderRef = useRef<MediaRecorder | null>(null);
  const userId = self?.memberId ?? null;

  const params = useParams();
  const pid = params.id;

  const isManualRecording = useRef(false); // üî• ÏÇ¨Ïö©ÏûêÍ∞Ä ÏßÅÏ†ë ÎÖπÏùå Î≤ÑÌäºÏùÑ ÎàåÎ†ÄÎäîÏßÄ Ï∂îÏ†Å

  // useEffect(): isRecording ÏÜåÏºì Í∞êÏßÄ Î∞è ÏûêÎèô ÎÖπÏùå Ïû¨ÏÉù / Ï†ïÏßÄ
  useEffect(() => {
    console.log("üîÑ `useEffect` Í∞êÏßÄ - isRecording Î≥ÄÍ≤ΩÎê®:", isRecording);

    if (!isManualRecording.current) {
      if (isRecording) {
        console.log("üî• ÏÜåÏºìÏóêÏÑú Î∞õÏùÄ recordingÏúºÎ°ú ÎÖπÏùå ÏãúÏûë");
        startRecordingFromSocket(); // üéØ ÏÉàÎ°úÏö¥ ÎÖπÏùå Ìï®Ïàò Ìò∏Ï∂ú
      } else {
        console.log("üî• ÏÜåÏºìÏóêÏÑú Î∞õÏùÄ recordingÏúºÎ°ú ÎÖπÏùå Ï†ïÏßÄ");
        stopRecordingFromSocket();
      }
    }
  }, [isRecording]);

  // useEffect: ÎèôÏòÅÏÉÅ Í∏∏Ïù¥ Ï¥àÍ≥ºÏãú, ÏûêÎèô Ï†ïÏßÄ (ÎÖπÏùåÏãú, ÎÖπÏùåÎèÑ Ï†ïÏßÄ)
  useEffect(() => {
    if (time >= duration) {
      if (isRecording) stopRecording();
      pause();
      reset();
    }
  }, [time, duration]);

  // useEffect: SpaceBar -> Ïû¨ÏÉù / ÏùºÏãú Ï†ïÏßÄ
  useEffect(() => {
    const handleKeyDown = (event: KeyboardEvent) => {
      const activeElement = document.activeElement;
      if (
        activeElement &&
        ["INPUT", "TEXTAREA"].includes(activeElement.tagName)
      ) {
        return;
      }
      if (event.code === "Space") {
        event.preventDefault();

        if (isPlaying) {
          sendPlaybackStatus({
            recording: isRecording,
            playState: "STOP",
            timelineMarker: 0,
          });
        } else {
          sendPlaybackStatus({
            recording: isRecording,
            playState: "PLAY",
            timelineMarker: 0,
          });
        }
      }
    };

    window.addEventListener("keydown", handleKeyDown);
    return () => {
      window.removeEventListener("keydown", handleKeyDown);
    };
  }, [isPlaying, play, pause]);

  // useEffect: ÎèôÏòÅÏÉÅ Í∏∏Ïù¥Ïóê ÎßûÍ≤å Ï†ÑÏ≤¥ duration ÏÑ§Ï†ï
  useEffect(() => {
    const videoElement = videoRef.current;

    if (!videoElement) return; // videoRefÍ∞Ä ÏïÑÏßÅ ÏÑ§Ï†ïÎêòÏßÄ ÏïäÏïòÎã§Î©¥ ÏïÑÎ¨¥Í≤ÉÎèÑ ÌïòÏßÄ ÏïäÏùå

    const handleMetadataLoaded = () => {
      setDuration(videoElement.duration || 0);
      console.log(
        "üìå ÎπÑÎîîÏò§ Î©îÌÉÄÎç∞Ïù¥ÌÑ∞ Î°úÎìúÎê®, duration:",
        videoElement.duration,
      );
    };

    // üéØ ÎπÑÎîîÏò§Ïùò `loadedmetadata` Ïù¥Î≤§Ìä∏Î•º Í∞êÏßÄÌïòÏó¨ `duration`ÏùÑ ÏÑ§Ï†ï
    videoElement.addEventListener("loadedmetadata", handleMetadataLoaded);

    // üéØ cleanup Ìï®ÏàòÏóêÏÑú Ïù¥Î≤§Ìä∏ Ï†úÍ±∞
    return () => {
      videoElement.removeEventListener("loadedmetadata", handleMetadataLoaded);
    };
  }, [videoRef]);

  // handleRecording(): ÎÖπÏùåÌïòÎäî Ìï®Ïàò
  const handleRecording = async () => {
    console.log("üé§ handleRecording Ïã§ÌñâÎê®! ÌòÑÏû¨ isRecording:", isRecording);

    if (!userId) {
      toast.warning("Ïò§Î•ò: ÏÇ¨Ïö©Ïûê Ï†ïÎ≥¥Í∞Ä ÏóÜÏñ¥, ÎÖπÏùåÏùÑ ÏãúÏûëÌï† Ïàò ÏóÜÏäµÎãàÎã§.");
      return;
    }

    sendPlaybackStatus({
      recording: !isRecording,
      playState: isRecording ? "STOP" : "PLAY",
      timelineMarker: isRecording ? 0 : time,
    });

    if (isRecording) {
      console.log("üõë ÎÖπÏùå Ï§ëÏßÄ Ï≤òÎ¶¨ Ï§ë...");
      mediaRecorderRef.current?.stop();
      stopRecording();

      if (audioContext) {
        audioContext.close();
        setAudioContext(null);
        setAnalyser(null);
      }

      setMediaRecorder(null);
      isManualRecording.current = false; // üî• ÎÖπÏùå Ï¢ÖÎ£å ÌõÑ ÌîåÎûòÍ∑∏ Ï¥àÍ∏∞Ìôî
      return;
    }

    console.log("üé¨ ÎÖπÏùå ÏãúÏûë!");
    isManualRecording.current = true; // üî• ÏÇ¨Ïö©ÏûêÍ∞Ä ÏßÅÏ†ë Ïã§ÌñâÌïú ÎÖπÏùå

    const currentTime = time;
    const activeMics = Object.entries(micStatus)
      .filter(([_, isOn]) => isOn)
      .map(([userId]) => userId);

    if (activeMics.length === 0) {
      toast.warning("Ïó≠Ìï† ÌÉ≠ÏóêÏÑú ÏûêÏã†Ïùò ÎßàÏù¥ÌÅ¨Î•º ÏºúÏ£ºÏÑ∏Ïöî!");
      return;
    }

    try {
      const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
      const recorder = new MediaRecorder(stream);
      mediaRecorderRef.current = recorder;

      const chunks: Blob[] = [];
      recorder.ondataavailable = (event) => {
        if (event.data.size > 0) {
          chunks.push(event.data);
        }
      };

      const track = tracks.find((t) => t.recorderId === userId);
      if (!track) {
        toast.warning("Ïò§ÎîîÏò§ Ìä∏ÎûôÏóê Ï∞∏Ïó¨ÏûêÎ•º Ìï†ÎãπÌï¥Ï£ºÏÑ∏Ïöî!");
        return;
      }

      recorder.onstop = async () => {
        toast.success("ÎÖπÏùåÎêú ÌååÏùºÏùÑ Ï†ÄÏû• Ï§ëÏûÖÎãàÎã§...");
        const audioBlob = new Blob(chunks, { type: "audio/wav" });
        const url = URL.createObjectURL(audioBlob);
        console.log("üéµ ÏÉùÏÑ±Îêú Ïò§ÎîîÏò§ ÌååÏùº URL:", url);

        if (!track.recorderId) {
          toast.error("Ìä∏ÎûôÏóê Ìï†ÎãπÎêú Ï∞∏Ïó¨ÏûêÍ∞Ä ÏóÜÏäµÎãàÎã§.");
          return;
        }
        const newUrl = await postAsset(String(pid), audioBlob);
        createAudioFile(track.trackId, newUrl, currentTime);
      };

      recorder.start();
      startRecording(track.trackId);
      setMediaRecorder(recorder);

      const AudioCtx = window.AudioContext;
      const audioCtx = new AudioCtx();
      const source = audioCtx.createMediaStreamSource(stream);
      const analyser = audioCtx.createAnalyser();
      analyser.fftSize = 2048;
      source.connect(analyser);

      setAudioContext(audioCtx);
      setAnalyser(analyser);
    } catch (error) {
      toast.error(`Ïò§Î•òÍ∞Ä Î∞úÏÉùÌñàÏäµÎãàÎã§. ${error}`);
    }
  };

  // startRecordingFromSocket(): ÏÜåÏºì ÏÉÅÌÉú Î∞õÏïÑÏÑú ÏûêÎèô ÎÖπÏùå ÏßÑÌñâ
  const startRecordingFromSocket = async () => {
    console.log("üé¨ [ÏÜåÏºì] ÎÖπÏùå ÏãúÏûë - isRecording ÏÉÅÌÉú:", isRecording);

    if (!userId) {
      toast.warning("Ïò§Î•ò: ÏÇ¨Ïö©Ïûê Ï†ïÎ≥¥Í∞Ä ÏóÜÏñ¥ ÎÖπÏùåÏùÑ ÏãúÏûëÌï† Ïàò ÏóÜÏäµÎãàÎã§.");
      return;
    }

    const currentTime = time;
    const activeMics = Object.entries(micStatus)
      .filter(([_, isOn]) => isOn)
      .map(([userId]) => userId);

    if (activeMics.length === 0) {
      toast.warning("Ïó≠Ìï† ÌÉ≠ÏóêÏÑú ÏûêÏã†Ïùò ÎßàÏù¥ÌÅ¨Î•º ÏºúÏ£ºÏÑ∏Ïöî!");
      return;
    }

    try {
      const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
      const recorder = new MediaRecorder(stream);
      mediaRecorderRef.current = recorder;

      const chunks: Blob[] = [];
      recorder.ondataavailable = (event) => {
        if (event.data.size > 0) {
          chunks.push(event.data);
        }
      };

      const track = tracks.find((t) => t.recorderId === userId);
      if (!track) {
        toast.warning("Ïò§ÎîîÏò§ Ìä∏ÎûôÏóê Ï∞∏Ïó¨ÏûêÎ•º Ìï†ÎãπÌï¥Ï£ºÏÑ∏Ïöî!");
        return;
      }

      recorder.onstop = async () => {
        toast.success("ÎÖπÏùåÎêú ÌååÏùºÏùÑ Ï†ÄÏû• Ï§ëÏûÖÎãàÎã§...");
        const audioBlob = new Blob(chunks, { type: "audio/webm" });
        const url = URL.createObjectURL(audioBlob);
        console.log("üéµ ÏÉùÏÑ±Îêú Ïò§ÎîîÏò§ ÌååÏùº URL:", url);

        if (!track.recorderId) {
          toast.error("Ìä∏ÎûôÏóê Ìï†ÎãπÎêú Ï∞∏Ïó¨ÏûêÍ∞Ä ÏóÜÏäµÎãàÎã§.");
          return;
        }

        const newUrl = await postAsset(String(pid), audioBlob);
        createAudioFile(track.trackId, newUrl, currentTime);
      };

      recorder.start();
      startRecording(track.trackId);
      setMediaRecorder(recorder);

      // Í∏∞Ï°¥ try Î∏îÎ°ùÏùò AudioContext Í¥ÄÎ†® Î°úÏßÅÎèÑ Ìè¨Ìï®
      const AudioCtx = window.AudioContext;
      const audioCtx = new AudioCtx();
      const source = audioCtx.createMediaStreamSource(stream);
      const analyser = audioCtx.createAnalyser();
      analyser.fftSize = 2048;
      source.connect(analyser);

      setAudioContext(audioCtx);
      setAnalyser(analyser);
    } catch (error) {
      toast.error(`Ïò§Î•òÍ∞Ä Î∞úÏÉùÌñàÏäµÎãàÎã§. ${error}`);
    }
  };

  // stopRecordingFromSocket(): ÏÜåÏºì ÏÉÅÌÉú Î∞õÏïÑ ÏûêÎèô ÎÖπÏùå Ï†ïÏßÄ
  const stopRecordingFromSocket = () => {
    console.log("üõë [ÏÜåÏºì] ÎÖπÏùå Ï§ëÏßÄ Ïã§ÌñâÎê®!");

    if (mediaRecorderRef.current) {
      mediaRecorderRef.current.stop();
    }

    stopRecording();

    if (audioContext) {
      audioContext.close();
      setAudioContext(null);
      setAnalyser(null);
    }

    setMediaRecorder(null);
  };

  // handlePlayButton(): Ïû¨ÏÉù/ÏùºÏãúÏ†ïÏßÄ Î≤ÑÌäº ÌÅ¥Î¶≠ Ìï®Ïàò
  const handlePlayButton = () => {
    if (isPlaying) {
      sendPlaybackStatus({
        recording: false,
        playState: "PAUSE",
        timelineMarker: time,
      });
    } else {
      sendPlaybackStatus({
        recording: false,
        playState: "PLAY",
        timelineMarker: time,
      });
    }
  };

  // handleStopButton(): Ï†ïÏßÄ Î≤ÑÌäº ÌÅ¥Î¶≠ Ìï®Ïàò
  const handleStopButton = () => {
    sendPlaybackStatus({
      recording: isRecording,
      playState: "STOP",
      timelineMarker: 0,
    });
  };

  return (
    <section className="flex h-full max-h-16 w-full flex-grow-0 flex-row items-center justify-between border border-gray-300 px-16 py-[22px]">
      <div className="flex h-full flex-row items-center justify-center gap-x-4">
        <div onClick={handleRecording} className="cursor-pointer">
          <RecordButton width={20} height={20} />
        </div>
        <div onClick={handlePlayButton} className="cursor-pointer">
          {isPlaying ? (
            <PauseButton width={20} height={20} />
          ) : (
            <PlayButton width={20} height={20} />
          )}
        </div>
        <div onClick={handleStopButton} className="cursor-pointer">
          <StopButton width={20} height={20} />
        </div>
      </div>
      <div className="flex h-full flex-row items-center justify-center gap-x-3">
        <H4 className="text-white-100">{formatTime(time)}</H4>
        <H4 className="text-white-100">/</H4>
        <H4 className="text-white-100">{formatTime(duration)}</H4>
      </div>
      <div className="flex h-full items-center justify-center gap-x-4">
        <ShareButton />
        <RenderingButton
          videoUrl={videoUrl}
          tracks={tracks}
          setTracks={setTracks}
        />
        <StoreButton tracks={tracks} assets={assets} />
      </div>
    </section>
  );
};

export default PlayBar;
