import { toast } from "sonner";
import { useParams } from "next/navigation";
import React, { useEffect, useRef, useState } from "react";

import { useMicStore } from "@/app/_store/MicStore";
import { useUserStore } from "@/app/_store/UserStore";
import { useTimeStore } from "@/app/_store/TimeStore";
import { useRecordingStore } from "@/app/_store/RecordingStore";

import { postAsset } from "@/app/_apis/studio";
import { Asset, Track } from "@/app/_types/studio";
import { formatTime } from "@/app/_utils/formatTime";

import H4 from "@/app/_components/H4";
import ShareButton from "./ShareButton";
import StoreButton from "./StoreButton";
import RenderingButton from "./RenderingButton";

import RecordButton from "@/public/images/icons/icon-record.svg";
import PlayButton from "@/public/images/icons/icon-play.svg";
import StopButton from "@/public/images/icons/icon-stop.svg";
import PauseButton from "@/public/images/icons/icon-pause.svg";
import { usePlaySocket } from "@/app/_hooks/usePlaySocket";

interface PlayBarProps {
  videoRef: React.RefObject<VideoElementWithCapturestream | null>;
  videoUrl: string | undefined;
  duration: number;
  setDuration: React.Dispatch<React.SetStateAction<number>>;
  tracks: Track[];
  setTracks: React.Dispatch<React.SetStateAction<Track[]>>;
  assets: Asset[];
}

const PlayBar = ({
  videoRef,
  videoUrl,
  duration,
  setDuration,
  tracks,
  setTracks,
  assets,
}: PlayBarProps) => {
  const { self } = useUserStore();
  const { micStatus } = useMicStore();
  const { time, isPlaying, play, pause, reset } = useTimeStore();
  const {
    isRecording,
    audioContext,
    startRecording,
    stopRecording,
    createAudioFile,
    setMediaRecorder,
    setAudioContext,
    setAnalyser,
  } = useRecordingStore();

  const { sendPlaybackStatus } = usePlaySocket();

  const mediaRecorderRef = useRef<MediaRecorder | null>(null);
  const userId = self?.memberId ?? null;

  const params = useParams();
  const pid = params.id;

  // useEffect: ë™ì˜ìƒ ê¸¸ì´ ì´ˆê³¼ì‹œ, ìžë™ ì •ì§€ (ë…¹ìŒì‹œ, ë…¹ìŒë„ ì •ì§€)
  useEffect(() => {
    if (time >= duration) {
      if (isRecording) stopRecording();
      pause();
      reset();
    }
  }, [time, duration]);

  // useEffect: SpaceBar -> ìž¬ìƒ / ì¼ì‹œ ì •ì§€
  useEffect(() => {
    const handleKeyDown = (event: KeyboardEvent) => {
      const activeElement = document.activeElement;
      if (
        activeElement &&
        ["INPUT", "TEXTAREA"].includes(activeElement.tagName)
      ) {
        return;
      }
      if (event.code === "Space") {
        event.preventDefault();

        if (isPlaying) {
          sendPlaybackStatus({
            isRecording: isRecording,
            playState: "PAUSE", // PAUSE ìƒíƒœë¡œ ë³´ë‚´ê¸°
          });
        } else {
          sendPlaybackStatus({
            isRecording: isRecording,
            playState: "PLAY", // PAUSE ìƒíƒœë¡œ ë³´ë‚´ê¸°
          });
        }
      }
    };

    window.addEventListener("keydown", handleKeyDown);
    return () => {
      window.removeEventListener("keydown", handleKeyDown);
    };
  }, [isPlaying, play, pause]);

  // useEffect: ë™ì˜ìƒ ê¸¸ì´ì— ë§žê²Œ ì „ì²´ duration ì„¤ì •
  useEffect(() => {
    const videoElement = videoRef.current;

    if (!videoElement) return; // videoRefê°€ ì•„ì§ ì„¤ì •ë˜ì§€ ì•Šì•˜ë‹¤ë©´ ì•„ë¬´ê²ƒë„ í•˜ì§€ ì•ŠìŒ

    const handleMetadataLoaded = () => {
      setDuration(videoElement.duration || 0);
      console.log(
        "ðŸ“Œ ë¹„ë””ì˜¤ ë©”íƒ€ë°ì´í„° ë¡œë“œë¨, duration:",
        videoElement.duration,
      );
    };

    // ðŸŽ¯ ë¹„ë””ì˜¤ì˜ `loadedmetadata` ì´ë²¤íŠ¸ë¥¼ ê°ì§€í•˜ì—¬ `duration`ì„ ì„¤ì •
    videoElement.addEventListener("loadedmetadata", handleMetadataLoaded);

    // ðŸŽ¯ cleanup í•¨ìˆ˜ì—ì„œ ì´ë²¤íŠ¸ ì œê±°
    return () => {
      videoElement.removeEventListener("loadedmetadata", handleMetadataLoaded);
    };
  }, [videoRef]);

  // handleRecording(): ë…¹ìŒí•˜ëŠ” í•¨ìˆ˜
  const handleRecording = async () => {
    if (!userId) {
      toast.warning("ì˜¤ë¥˜: ì‚¬ìš©ìž ì •ë³´ê°€ ì—†ì–´, ë…¹ìŒì„ ì‹œìž‘í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.");
      return;
    }

    if (isRecording) {
      sendPlaybackStatus({
        isRecording: false,
        playState: "STOP",
      });

      mediaRecorderRef.current?.stop();
      stopRecording();

      if (audioContext) {
        audioContext.close();
        setAudioContext(null);
        setAnalyser(null);
      }
      setMediaRecorder(null);
    } else {
      const currentTime = time;
      const activeMics = Object.entries(micStatus)
        .filter(([_, isOn]) => isOn)
        .map(([userId]) => userId);

      if (activeMics.length === 0) {
        toast.warning("ì—­í•  íƒ­ì—ì„œ ìžì‹ ì˜ ë§ˆì´í¬ë¥¼ ì¼œì£¼ì„¸ìš”!");
        return;
      }

      try {
        const stream = await navigator.mediaDevices.getUserMedia({
          audio: true,
        });
        const recorder = new MediaRecorder(stream);
        mediaRecorderRef.current = recorder;

        const chunks: Blob[] = [];
        recorder.ondataavailable = (event) => {
          console.log("ë°ì´í„° ì €ìž¥ë¨:", event.data);
          if (event.data.size > 0) {
            chunks.push(event.data);
          }
        };

        const track = tracks.find((t) => t.recorderId === userId);
        if (!track) {
          toast.warning("ì˜¤ë””ì˜¤ íŠ¸ëž™ì— ì°¸ì—¬ìžë¥¼ í• ë‹¹í•´ì£¼ì„¸ìš”!");
          return;
        }

        recorder.onstop = async () => {
          toast.success("ë…¹ìŒëœ íŒŒì¼ì„ ì €ìž¥ ì¤‘ìž…ë‹ˆë‹¤...");
          const audioBlob = new Blob(chunks, {
            type: "audio/wav",
          });
          const url = URL.createObjectURL(audioBlob);
          console.log("ðŸŽµ ìƒì„±ëœ ì˜¤ë””ì˜¤ íŒŒì¼ URL:", url);

          if (!track.recorderId) {
            toast.error(
              "íŠ¸ëž™ì— í• ë‹¹ëœ ì°¸ì—¬ìžê°€ ì—†ìŠµë‹ˆë‹¤. ë…¹ìŒ íŒŒì¼ ì¶”ê°€ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.",
            );
            return;
          }

          const newUrl = await postAsset(String(pid), audioBlob);
          createAudioFile(track.trackId, newUrl, currentTime);
        };

        recorder.start();
        startRecording(track.trackId);
        setMediaRecorder(recorder);

        // ðŸ”¥ ì†Œì¼“ì— ë…¹ìŒ ì‹œìž‘ ìƒíƒœ ì „ì†¡
        sendPlaybackStatus({
          isRecording: true,
          playState: "PLAY",
        });

        const AudioCtx = window.AudioContext;
        const audioCtx = new AudioCtx();
        const source = audioCtx.createMediaStreamSource(stream);
        const analyser = audioCtx.createAnalyser();
        analyser.fftSize = 2048;
        source.connect(analyser);

        setAudioContext(audioCtx);
        setAnalyser(analyser);
      } catch (error) {
        toast.error(`ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ${error}`);
      }
    }
  };

  // handlePlayButton(): ìž¬ìƒ/ì¼ì‹œì •ì§€ ë²„íŠ¼ í´ë¦­ í•¨ìˆ˜
  const handlePlayButton = () => {
    if (isPlaying) {
      sendPlaybackStatus({
        isRecording: false,
        playState: "PAUSE",
      });
    } else {
      sendPlaybackStatus({
        isRecording: false,
        playState: "PLAY",
      });
    }
  };

  // handleStopButton(): ì •ì§€ ë²„íŠ¼ í´ë¦­ í•¨ìˆ˜
  const handleStopButton = () => {
    sendPlaybackStatus({
      isRecording: isRecording,
      playState: "STOP",
    });
  };

  return (
    <section className="flex h-full max-h-16 w-full flex-grow-0 flex-row items-center justify-between border border-gray-300 px-16 py-[22px]">
      <div className="flex h-full flex-row items-center justify-center gap-x-4">
        <div onClick={handleRecording} className="cursor-pointer">
          <RecordButton width={20} height={20} />
        </div>
        <div onClick={handlePlayButton} className="cursor-pointer">
          {isPlaying ? (
            <PauseButton width={20} height={20} />
          ) : (
            <PlayButton width={20} height={20} />
          )}
        </div>
        <div onClick={handleStopButton} className="cursor-pointer">
          <StopButton width={20} height={20} />
        </div>
      </div>
      <div className="flex h-full flex-row items-center justify-center gap-x-3">
        <H4 className="text-white-100">{formatTime(time)}</H4>
        <H4 className="text-white-100">/</H4>
        <H4 className="text-white-100">{formatTime(duration)}</H4>
      </div>
      <div className="flex h-full items-center justify-center gap-x-4">
        <ShareButton />
        <RenderingButton
          videoUrl={videoUrl}
          tracks={tracks}
          setTracks={setTracks}
        />
        <StoreButton tracks={tracks} assets={assets} />
      </div>
    </section>
  );
};

export default PlayBar;
