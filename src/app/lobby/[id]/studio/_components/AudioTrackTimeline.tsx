"use client";

import React, { useEffect, useRef, useState } from "react";
import { useDrop } from "react-dnd"; // âœ… useDrop ì¶”ê°€
import { AudioFile, PX_PER_SECOND, Track } from "@/app/_types/studio";
import AudioBlock from "./AudioBlock";
import { useRecordingStore } from "@/app/_store/RecordingStore";
import LiveAudioBlock from "./LiveAudioBlock";
import { useTimeStore } from "@/app/_store/TimeStore";
import { useUserStore } from "@/app/_store/UserStore";
import { useAssetsStore } from "@/app/_store/AssetsStore";
import { findPossibleId } from "@/app/_utils/findPossibleId";
import { createBlob } from "@/app/_utils/audioUtils";
import { postAsset } from "@/app/_apis/studio";
import { useParams } from "next/navigation";

interface AudioTrackTimelineProps {
  trackId: number;
  isMuted: boolean;
  files: AudioFile[];
  duration: number;
  setDuration: React.Dispatch<React.SetStateAction<number>>;
  waveColor: string;
  blockColor: string;
  audioContext: AudioContext | null;
  audioBuffers: Map<string, AudioBuffer> | null;
  setTracks: React.Dispatch<React.SetStateAction<Track[]>>;
}

const AudioTrackTimeline = ({
  trackId,
  isMuted, // íŠ¸ëž™ë³„ ìŒì†Œê±° ì—¬ë¶€ë¶€
  files,
  duration,
  setDuration,
  waveColor,
  blockColor,
  audioContext,
  audioBuffers,
  setTracks,
}: AudioTrackTimelineProps) => {
  const timelineRef = useRef<HTMLDivElement | null>(null);
  const {
    audioFiles,
    offsetMap,
    isRecording,
    analyser,
    currentRecordingTrackId,
    setAudioFiles,
  } = useRecordingStore();
  const { time } = useTimeStore();
  const { studioMembers, self } = useUserStore();
  const { audioFiles: assetAudioFiles, addAudioFile } = useAssetsStore();
  const isSyncingRef = useRef(false);
  const lastFilesRef = useRef("");
  const [liveWidth, setLiveWidth] = useState(0);
  const initialXRef = useRef<number | null>(null);
  const recordStartRef = useRef<number | null>(null);
  const animationIdRef = useRef<number | null>(null);
  const params = useParams();
  const pid = params.id;

  useEffect(() => {
    if (isRecording && currentRecordingTrackId == trackId) {
      // ë…¹ìŒ ì‹œìž‘
      if (initialXRef.current === null) {
        initialXRef.current = time * PX_PER_SECOND;
      }
      setLiveWidth(1);
      recordStartRef.current = performance.now();
      startWidthLoop();
    } else {
      if (recordStartRef.current) {
        setLiveWidth(0);
      }
      recordStartRef.current = null;
      initialXRef.current = null;

      if (animationIdRef.current) {
        cancelAnimationFrame(animationIdRef.current);
        animationIdRef.current = null;
      }
    }

    return () => {
      if (animationIdRef.current) cancelAnimationFrame(animationIdRef.current);
    };
  }, [isRecording, time]);

  const startWidthLoop = () => {
    const updateWidth = () => {
      if (!recordStartRef.current) return;
      const currentX = time * PX_PER_SECOND;
      setLiveWidth(Math.max(1, currentX - (initialXRef.current ?? 0)));
      animationIdRef.current = requestAnimationFrame(updateWidth);
    };
    updateWidth();
  };

  //ì„œë²„ë¡œ ë³€ê²½ì‚¬í•­ ì „ì†¡
  useEffect(() => {
    const newFilesString = JSON.stringify(files);

    if (!isSyncingRef.current && lastFilesRef.current !== newFilesString) {
      console.log(`ðŸ“¤ íŠ¸ëž™(${trackId})ì˜ ë³€ê²½ ì‚¬í•­ ì„œë²„ë¡œ ì „ì†¡`, {
        trackId,
        files,
      });

      // socket.emit("update-track-files", {
      //   trackId,
      //   updatedFiles: files,
      // });

      setTracks((prevTracks) =>
        prevTracks.map((track) => {
          if (track.trackId !== trackId) return track;

          return { ...track, files: files.map((f) => ({ ...f })) };
        }),
      );
      isSyncingRef.current = true;
      lastFilesRef.current = newFilesString;
      setTimeout(() => {
        isSyncingRef.current = false;
      }, 300);
    } else {
      console.log(`âš ï¸ íŠ¸ëž™(${trackId}) ë³€ê²½ ì—†ìŒ -> ì„œë²„ ì „ì†¡ ìƒëžµ`);
    }
  }, [files.map((f) => JSON.stringify(f)).join(","), trackId]);

  //ë…¹ìŒëœ íŒŒì¼ì„ ì¶”ê°€í•˜ëŠ” ì—­í• 
  useEffect(() => {
    console.log(`ðŸŽ™ï¸ íŠ¸ëž™(${trackId})ì˜ ë…¹ìŒëœ íŒŒì¼ ì¶”ê°€ í™•ì¸:`, audioFiles);

    // ì¶”ê°€ë˜ëŠ” ì˜¤ë””ì˜¤ ê¸¸ì´ ê³„ì‚°
    const loadAudioDuration = async (url: string) => {
      if (!audioContext) return 0;
      try {
        const response = await fetch(url);
        const arrayBuffer = await response.arrayBuffer();
        const audioBuffer = await audioContext.decodeAudioData(arrayBuffer);

        if (audioBuffers) {
          audioBuffers.set(url, audioBuffer);
        }

        // console.log(`âœ… ${url}ì˜ ì˜¤ë””ì˜¤ ê¸¸ì´:`, audioBuffer.duration);
        return audioBuffer.duration;
      } catch (error) {
        console.error(`âŒ ${url} ì˜¤ë””ì˜¤ ë¡œë“œ ì‹¤íŒ¨:`, error);
        return 0;
      }
    };

    // ë…¹ìŒëœ íŒŒì¼ audioContextë¡œ ì¶”ê°€
    const updateTrack = async () => {
      const existingFilesUrls = new Set(files.map((file) => file.url));

      const newFiles = await Promise.all(
        (audioFiles[trackId] ?? [])
          .filter((url) => !existingFilesUrls.has(url))
          .map(async (url) => {
            const duration = await loadAudioDuration(url);
            const buffer =
              audioBuffers?.get(url) ??
              new AudioBuffer({ length: 1, sampleRate: 44100 });
            const blob = await createBlob(buffer);
            const newUrl = await postAsset(String(pid), blob);

            if (duration <= 0) {
              console.warn(`âš ï¸ ${url}ì˜ durationì´ 0ì´ˆ ì´í•˜ë¡œ ìž˜ëª» ê³„ì‚°ë¨`);
              return null;
            }

            const starPoint = offsetMap[url] || 0;

            const createdFile = {
              // id: `${trackId}-${Date.now()}`,
              id: findPossibleId(assetAudioFiles, studioMembers, "ë‚˜"),
              url: newUrl,
              startPoint: starPoint,
              duration,
              trimStart: 0,
              trimEnd: 0,
              volume: 1,
              isMuted: isMuted,
              speed: 1,
            };
            addAudioFile(createdFile);
            return createdFile;
          }),
      );

      const validFiles = newFiles.filter((file) => file !== null);

      if (validFiles.length === 0) {
        console.log(`âš ï¸ íŠ¸ëž™(${trackId})ì— ì¶”ê°€í•  ìœ íš¨í•œ íŒŒì¼ì´ ì—†ìŒ`);
        return;
      }

      setTracks((prevTracks) =>
        prevTracks.map((track) => {
          if (track.trackId !== trackId) return track;

          const existingFiles = [...track.files];
          const updatedFiles = [...existingFiles, ...validFiles];

          if (JSON.stringify(existingFiles) === JSON.stringify(updatedFiles)) {
            console.log(`âš ï¸ íŠ¸ëž™(${trackId}) íŒŒì¼ ë³€ê²½ ì—†ìŒ, ì—…ë°ì´íŠ¸ ìƒëžµ`);
            return track;
          }

          console.log(
            `ðŸŽ¶ íŠ¸ëž™(${trackId})ì— ë…¹ìŒëœ íŒŒì¼ ì¶”ê°€ë¨:`,
            updatedFiles,
          );
          return {
            ...track,
            files: updatedFiles,
          };
        }),
      );

      setAudioFiles((prev) => ({
        ...prev,
        [trackId]: (prev[trackId] ?? []).filter(
          (url) => !validFiles.some((file) => file.url === url),
        ),
      }));

      validFiles.forEach((file) => {
        delete offsetMap[file.url];
      });
    };

    updateTrack();
  }, [
    // audioFiles,
    setAudioFiles,
    trackId,
    setTracks,
    audioContext,
    audioBuffers,
  ]);

  // âœ… ë“œë¡­ ê°€ëŠ¥í•˜ë„ë¡ `useDrop` ì¶”ê°€
  const [{ isOver }, drop] = useDrop(() => ({
    accept: "ASSET", // ë“œëž˜ê·¸ ê°€ëŠ¥í•œ ì•„ì´í…œ íƒ€ìž…
    drop: (item: { id: string; url: string }, monitor) => {
      if (!timelineRef.current) return;

      // í˜„ìž¬ ë“œë¡­í•œ ìœ„ì¹˜ë¥¼ ì´ˆ ë‹¨ìœ„ë¡œ ë³€í™˜
      const offset = monitor.getClientOffset();
      if (!offset) return;

      const rect = timelineRef.current.getBoundingClientRect();
      const dropX = offset.x - rect.left;
      const startPoint = Math.max(0, Math.round((dropX / 80) * 100) / 100); // 80px = 1ì´ˆ ê¸°ì¤€

      setTracks((prevTracks) =>
        prevTracks.map((track) =>
          track.trackId === trackId
            ? {
                ...track,
                files: [
                  ...track.files,
                  {
                    id: `${item.id}-${Date.now()}`,
                    url: item.url,
                    startPoint,
                    duration: 5, // ê¸°ë³¸ 5ì´ˆ ê¸¸ì´
                    trimStart: 0,
                    trimEnd: 0,
                    volume: 1,
                    isMuted: false, // ê¸°ë³¸ false
                    speed: 1,
                  },
                ],
              }
            : track,
        ),
      );
    },
    collect: (monitor) => ({
      isOver: !!monitor.isOver(),
    }),
  }));

  return (
    <div
      ref={(node) => {
        drop(node);
        timelineRef.current = node;
      }}
      className={`relative flex h-[60px] min-h-0 flex-shrink-0 flex-row items-center justify-start overflow-y-hidden border border-gray-300 ${
        isOver ? "bg-gray-200" : ""
      }`} // ë“œë¡­ ì‹œ ìƒ‰ìƒ ë³€ê²½
      style={{ width: `${duration * 80}px` }}
    >
      <div className="relative flex h-full items-center justify-center">
        {files.map((file, index) => {
          const width = `${
            (file.duration - file.trimStart - file.trimEnd) * 80
          }px`;

          return (
            <div
              key={file.id}
              className="relative flex items-center justify-start"
            >
              <AudioBlock
                file={{ ...file, isMuted: isMuted }} // ì¶”ê°€
                trackId={trackId}
                fileIdx={index}
                width={width}
                waveColor={waveColor}
                blockColor={blockColor}
                audioContext={audioContext}
                audioBuffers={audioBuffers}
                setTracks={setTracks}
                timelineRef={timelineRef}
              />
            </div>
          );
        })}

        {isRecording && currentRecordingTrackId === trackId && analyser && (
          <LiveAudioBlock
            waveClolor={waveColor}
            isRecording={isRecording}
            analyser={analyser}
            blockColor={blockColor}
            width={liveWidth}
            initialX={initialXRef.current ?? 0}
          />
        )}
      </div>
    </div>
  );
};

export default AudioTrackTimeline;
