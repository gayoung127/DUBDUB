"use client";

import React, { useEffect, useRef } from "react";
import { useDrop } from "react-dnd"; // âœ… useDrop ì¶”ê°€
import { AudioFile, Track } from "@/app/_types/studio";
import AudioBlock from "./AudioBlock";
import { useRecordingStore } from "@/app/_store/RecordingStore";

interface AudioTrackTimelineProps {
  trackId: number;
  files: AudioFile[];
  totalDuration: number;
  waveColor: string;
  blockColor: string;
  audioContext: AudioContext | null;
  audioBuffers: Map<string, AudioBuffer> | null;
  setTracks: React.Dispatch<React.SetStateAction<Track[]>>;
}

const AudioTrackTimeline = ({
  trackId,
  files,
  totalDuration,
  waveColor,
  blockColor,
  audioContext,
  audioBuffers,
  setTracks,
}: AudioTrackTimelineProps) => {
  const timelineRef = useRef<HTMLDivElement | null>(null);
  const { audioFiles } = useRecordingStore();

  useEffect(() => {
    console.log(`ðŸŽ™ï¸ íŠ¸ëž™(${trackId})ì˜ ë…¹ìŒëœ íŒŒì¼ ì¶”ê°€ í™•ì¸:`, audioFiles);

    // ì¶”ê°€ë˜ëŠ” ì˜¤ë””ì˜¤ ê¸¸ì´ ê³„ì‚°
    const loadAudioDuration = async (url: string) => {
      if (!audioContext) return 0;
      try {
        const response = await fetch(url);
        const arrayBuffer = await response.arrayBuffer();
        const audioBuffer = await audioContext.decodeAudioData(arrayBuffer);

        if (audioBuffers) {
          audioBuffers.set(url, audioBuffer);
        }

        // console.log(`âœ… ${url}ì˜ ì˜¤ë””ì˜¤ ê¸¸ì´:`, audioBuffer.duration);
        return audioBuffer.duration;
      } catch (error) {
        console.error(`âŒ ${url} ì˜¤ë””ì˜¤ ë¡œë“œ ì‹¤íŒ¨:`, error);
        return 0;
      }
    };

    // ë…¹ìŒë¨ íŒŒì¼ audioContextë¡œ ì¶”ê°€
    const updateTracks = async () => {
      const newFiles = await Promise.all(
        (audioFiles[trackId] ?? []).map(async (url) => {
          const duration = await loadAudioDuration(url);

          if (duration <= 0) {
            console.warn(`âš ï¸ ${url}ì˜ durationì´ 0ì´ˆ ì´í•˜ë¡œ ìž˜ëª» ê³„ì‚°ë¨`);
            return null;
          }

          return {
            id: `${trackId}-${Date.now()}`,
            url,
            startPoint: 0,
            duration,
            trimStart: 0,
            trimEnd: 0,
            volume: 1,
            isMuted: false,
            speed: 1,
          };
        }),
      );

      const validFiles = newFiles.filter((file) => file !== null);

      if (validFiles.length === 0) {
        console.log(`âš ï¸ íŠ¸ëž™(${trackId})ì— ì¶”ê°€í•  ìœ íš¨í•œ íŒŒì¼ì´ ì—†ìŒ`);
        return;
      }

      setTracks((prevTracks) =>
        prevTracks.map((track) => {
          if (track.trackId !== trackId) return track;

          const existingFiles = [...track.files];
          const updatedFiles = [...existingFiles, ...validFiles];

          if (JSON.stringify(existingFiles) === JSON.stringify(updatedFiles)) {
            console.log(`âš ï¸ íŠ¸ëž™(${trackId}) íŒŒì¼ ë³€ê²½ ì—†ìŒ, ì—…ë°ì´íŠ¸ ìƒëžµ`);
            return track;
          }

          console.log(
            `ðŸŽ¶ íŠ¸ëž™(${trackId})ì— ë…¹ìŒëœ íŒŒì¼ ì¶”ê°€ë¨:`,
            updatedFiles,
          );
          return {
            ...track,
            files: updatedFiles,
          };
        }),
      );
    };

    updateTracks();
  }, [audioFiles, trackId, setTracks, audioContext, audioBuffers]);

  // âœ… ë“œë¡­ ê°€ëŠ¥í•˜ë„ë¡ `useDrop` ì¶”ê°€
  const [{ isOver }, drop] = useDrop(() => ({
    accept: "ASSET", // ë“œëž˜ê·¸ ê°€ëŠ¥í•œ ì•„ì´í…œ íƒ€ìž…
    drop: (item: { id: string; url: string }, monitor) => {
      if (!timelineRef.current) return;

      // í˜„ìž¬ ë“œë¡­í•œ ìœ„ì¹˜ë¥¼ ì´ˆ ë‹¨ìœ„ë¡œ ë³€í™˜
      const offset = monitor.getClientOffset();
      if (!offset) return;

      const rect = timelineRef.current.getBoundingClientRect();
      const dropX = offset.x - rect.left;
      const startPoint = Math.max(0, Math.round(dropX / 80)); // 80px = 1ì´ˆ ê¸°ì¤€

      setTracks((prevTracks) =>
        prevTracks.map((track) =>
          track.trackId === trackId
            ? {
                ...track,
                files: [
                  ...track.files,
                  {
                    id: `${item.id}-${Date.now()}`,
                    url: item.url,
                    startPoint,
                    duration: 5, // ê¸°ë³¸ 5ì´ˆ ê¸¸ì´
                    trimStart: 0,
                    trimEnd: 0,
                    volume: 1,
                    isMuted: false,
                    speed: 1,
                  },
                ],
              }
            : track,
        ),
      );
    },
    collect: (monitor) => ({
      isOver: !!monitor.isOver(),
    }),
  }));

  return (
    <div
      ref={(node) => {
        drop(node);
        timelineRef.current = node;
      }}
      className={`flex h-[60px] min-h-0 flex-shrink-0 flex-row items-center justify-start overflow-y-hidden border border-gray-300 ${
        isOver ? "bg-gray-200" : ""
      }`} // ë“œë¡­ ì‹œ ìƒ‰ìƒ ë³€ê²½
      style={{ width: `${totalDuration * 80}px` }}
    >
      <div className="relative flex h-full items-center justify-center">
        {files.map((file, index) => {
          const width = `${
            (file.duration - file.trimStart - file.trimEnd) * 80
          }px`;

          return (
            <div
              key={file.id}
              className="relative flex items-center justify-start"
            >
              <AudioBlock
                file={file}
                width={width}
                waveColor={waveColor}
                blockColor={blockColor}
                audioContext={audioContext}
                audioBuffers={audioBuffers}
                setTracks={setTracks}
                timelineRef={timelineRef}
              />
            </div>
          );
        })}
      </div>
    </div>
  );
};

export default AudioTrackTimeline;
