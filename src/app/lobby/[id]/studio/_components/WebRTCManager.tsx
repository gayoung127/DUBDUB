/* eslint-disable @typescript-eslint/no-unused-expressions */

/*
ì—­í• 
1. OpenVidu ì„¸ì…˜ì„ ìƒì„±í•˜ê³  ê´€ë¦¬
2. ì„œë²„ì—ì„œ ì„¸ì…˜ IDì™€ í† í°ì„ ê°€ì ¸ì™€ OpenViduì™€ ì—°ê²°
3. ì˜¤ë””ì˜¤ ìŠ¤íŠ¸ë¦¼ì„ OpenViduì— ì¶”ê°€í•˜ê³  ë‹¤ë¥¸ ì‚¬ìš©ìì™€ ê³µìœ 
*/
import { useMicStore } from "@/app/_store/MicStore";
import { useTimeStore } from "@/app/_store/TimeStore";
import {
  OpenVidu,
  Publisher,
  Session,
  Subscriber,
  Stream,
  SignalEvent,
} from "openvidu-browser";
import { useEffect, useRef, useState } from "react";
import { toast } from "sonner";
/*
isPlaying â†’ ë¹„ë””ì˜¤ ì¬ìƒ ìƒíƒœ
time â†’ í˜„ì¬ ì¬ìƒ ìœ„ì¹˜
 */
interface WebRTCManagerProps {
  studioId: number;
  sessionId: string;
  sessionToken: string;
  userId: number;
  onUserAudioUpdate: (userId: number, stream: MediaStream) => void;
}

const WebRTCManager = ({
  studioId,
  sessionId,
  sessionToken,
  userId,
  onUserAudioUpdate,
}: WebRTCManagerProps) => {
  const openViduRef = useRef<OpenVidu | null>(null);
  const sessionRef = useRef<Session | null>(null);
  const [session, setSession] = useState<Session | null>(null);
  const [publisher, setPublisher] = useState<Publisher | null>(null);
  const [subscribers, setSubscribers] = useState<Subscriber[]>([]);
  const { micStatus, setMicStatus } = useMicStore();

  useEffect(() => {
    if (session) sessionRef.current = session;
    console.log("ğŸ§ í˜„ì¬ êµ¬ë… ì¤‘ì¸ ìŠ¤íŠ¸ë¦¼:", subscribers);
  }, [session, subscribers]);

  // ë§ˆì´í¬ ì ‘ê·¼ ê¶Œí•œ í™•ì¸
  const checkAudioPermissions = async () => {
    try {
      const stream = await navigator.mediaDevices.getUserMedia({
        video: false,
        audio: true,
      });

      stream.getTracks().forEach((track) => track.stop());
      return true;
    } catch (error) {
      console.error("ğŸš¨ ë§ˆì´í¬ ì ‘ê·¼ ê±°ë¶€ë¨:", error);
      toast.warning("ë§ˆì´í¬ ê¶Œí•œì´ í•„ìš”í•©ë‹ˆë‹¤.");
      return false;
    }
  };

  // OpenVidu ì„¸ì…˜ ì´ˆê¸°í™”
  useEffect(() => {
    const initSession = async () => {
      try {
        if (!sessionToken) return;
        openViduRef.current = new OpenVidu();

        const newSession = openViduRef.current.initSession();
        sessionRef.current = newSession;
        setSession(newSession);

        newSession.on("streamCreated", handleStreamCreated);
        newSession.on("streamDestroyed", handleStreamDestroyed);
        newSession.on("signal:mic-status", handleMicStatusSignal);

        await newSession.connect(sessionToken, JSON.stringify({ userId }));
        console.log("âœ… OpenVidu ì„¸ì…˜ì— ì—°ê²°ë¨");

        const hasPermissions = await checkAudioPermissions();
        if (!hasPermissions) {
          toast.warning("ë§ˆì´í¬ ê¶Œí•œì´ í•„ìš”í•©ë‹ˆë‹¤.");
          return;
        }

        if (newSession.connection) {
          await publishAudioStream(newSession);

          newSession.remoteConnections.forEach((connection) => {
            if (connection.stream) {
              handleStreamCreated({ stream: connection.stream });
            }
          });
        } else {
          console.warn(
            "ğŸš¨ ì„¸ì…˜ ì—°ê²°ì´ ì™„ë£Œë˜ì§€ ì•Šì•„ syncRequest ì‹ í˜¸ë¥¼ ë³´ë‚¼ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.",
          );
        }
      } catch (error) {
        console.error("OpenVidu ì„¸ì…˜ ì´ˆê¸°í™” ì‹¤íŒ¨: ", error);
      }
    };

    initSession();

    return () => {
      console.log("ğŸ”Œ ì„¸ì…˜ ì¢…ë£Œ");

      if (sessionRef.current) {
        sessionRef.current.off("streamCreated", handleStreamCreated);
        sessionRef.current.off("streamDestroyed", handleStreamDestroyed);
        sessionRef.current.off("signal:mic-status", handleMicStatusSignal);
        sessionRef.current.disconnect();
      }

      setTimeout(() => {
        setSubscribers([]);
      }, 100);
      setPublisher(null);
      openViduRef.current = null;
    };
  }, [sessionToken]);

  // ì˜¤ë””ì˜¤ ìŠ¤íŠ¸ë¦¼ í¼ë¸”ë¦¬ì‹±
  const publishAudioStream = async (session: Session) => {
    try {
      if (!openViduRef.current || !session.connection) {
        console.error("ğŸš¨ OpenVidu ì¸ìŠ¤í„´ìŠ¤ ë˜ëŠ” ì„¸ì…˜ ì—°ê²°ì´ ì—†ìŒ");
        return;
      }

      const audioStream = await navigator.mediaDevices.getUserMedia({
        audio: true,
      });
      console.log("ğŸ¤ ë§ˆì´í¬ ìŠ¤íŠ¸ë¦¼ ê°€ì ¸ì˜¤ê¸° ì„±ê³µ:", audioStream);

      if (!audioStream || !audioStream.getAudioTracks().length) {
        console.error("ğŸš¨ ì˜¤ë””ì˜¤ íŠ¸ë™ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.");
        return;
      }

      const newAudioPublisher = session.openvidu.initPublisher(undefined, {
        videoSource: false,
        audioSource: undefined,
        publishAudio: true,
      });

      if (!newAudioPublisher) {
        console.error("ğŸš¨ ì˜¤ë””ì˜¤ í¼ë¸”ë¦¬ì…” ìƒì„± ì‹¤íŒ¨");
        return;
      }

      console.log("ğŸ“¡ ì˜¤ë””ì˜¤ í¼ë¸”ë¦¬ì…” ìƒì„± ì„±ê³µ, ì„¸ì…˜ì— ë°œí–‰ ì¤‘...");
      await session.publish(newAudioPublisher);
      console.log("âœ… ì˜¤ë””ì˜¤ í¼ë¸”ë¦¬ì‹± ì™„ë£Œ");
      console.log(
        "ğŸ“¡ ì˜¤ë””ì˜¤ í¼ë¸”ë¦¬ì…” ìƒíƒœ:",
        newAudioPublisher.stream.audioActive,
      );

      setPublisher(newAudioPublisher);

      onUserAudioUpdate(userId, newAudioPublisher.stream.getMediaStream());
      console.log("ì˜¤ë””ì˜¤ ìŠ¤íŠ¸ë¦¼ ì„¤ì • ì„±ê³µ: ");
    } catch (error) {
      console.error("ì˜¤ë””ì˜¤ ìŠ¤íŠ¸ë¦¼ ì„¤ì • ì‹¤íŒ¨: ", error);
    }
  };

  // ìƒˆë¡œìš´ ìŠ¤íŠ¸ë¦¼ ìƒì„± ì‹œ
  const handleStreamCreated = (event: { stream: Stream }) => {
    const currentSession = sessionRef.current;
    if (!currentSession) {
      console.error("ğŸš¨ handleStreamCreated: ì„¸ì…˜ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŒ");
      return;
    }

    try {
      console.log("ğŸ“Œ ìƒˆë¡œìš´ ìŠ¤íŠ¸ë¦¼ì´ ìƒì„±ë¨:", event.stream);
      const subscriber = currentSession.subscribe(event.stream, undefined);
      if (!subscriber) {
        console.warn("âš ï¸ êµ¬ë…ì ìƒì„± ì‹¤íŒ¨");
        return;
      }

      const mediaStream = subscriber.stream.getMediaStream();
      console.log("ğŸµ êµ¬ë…í•œ ë¯¸ë””ì–´ ìŠ¤íŠ¸ë¦¼:", mediaStream);

      if (!mediaStream || mediaStream.getAudioTracks().length === 0) {
        console.warn("âš ï¸ ìœ íš¨í•œ ì˜¤ë””ì˜¤ íŠ¸ë™ì´ ì—†ìŒ");
        return;
      }

      mediaStream.getAudioTracks().forEach((track) => {
        track.enabled = true;
      });

      setSubscribers((prev) => [...prev, subscriber]);

      const connectionData = JSON.parse(event.stream.connection.data);
      const remoteUserId = connectionData.userId;
      onUserAudioUpdate(remoteUserId, mediaStream);
    } catch (error) {}
  };

  // ìŠ¤íŠ¸ë¦¼ ì œê±°
  const handleStreamDestroyed = (event: { stream: Stream }) => {
    if (!event.stream || !event.stream.connection) return;

    console.log("ğŸ›‘ ìŠ¤íŠ¸ë¦¼ ì œê±°ë¨:", event.stream.connection.connectionId);

    setSubscribers((prev) => prev.filter((sub) => sub.stream !== event.stream));
  };

  // ë§ˆì´í¬ ìƒíƒœ ì „ì†¡
  const handleSendMicstatus = (userId: number, isMicOn: boolean) => {
    if (!sessionRef.current) {
      console.warn(
        "âš ï¸ [handleSendMicstatus] ì„¸ì…˜ì´ ì¡´ì¬í•˜ì§€ ì•Šì•„ ì‹ í˜¸ë¥¼ ë³´ë‚¼ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.",
      );
      return;
    }

    sessionRef.current
      .signal({
        type: "mic-status",
        data: JSON.stringify({ userId, isMicOn }),
      })
      .catch((error) => console.error("Signal Error:", error));
  };

  // ë§ˆì´í¬ ìƒíƒœ ë³€ê²½ ì‹œ ì „ì†¡
  useEffect(() => {
    if (!sessionRef.current || micStatus[userId] === undefined) return;
    console.log(
      `ğŸ“¡ [handleSendMicstatus] ë‚´ ë§ˆì´í¬ ìƒíƒœ ë³€ê²½ ì „ì†¡ ì¤€ë¹„ - í˜„ì¬ ìƒíƒœ: ${micStatus[userId]}`,
    );

    if (micStatus[userId] === publisher?.stream.audioActive) return;
    console.log(
      `ğŸ“¡ [handleSendMicstatus] ë‚´ ë§ˆì´í¬ ìƒíƒœ ë³€ê²½ ì „ì†¡: ${micStatus[userId]}`,
    );
    handleSendMicstatus(userId, micStatus[userId]);
  }, [micStatus[userId]]);

  // í¼ë¸”ë¦¬ì…”ì˜ ì˜¤ë””ì˜¤ ìƒíƒœ ê´€ë¦¬
  useEffect(() => {
    if (publisher && micStatus[userId] !== publisher.stream.audioActive) {
      if (micStatus[userId]) {
        navigator.mediaDevices
          .getUserMedia({ audio: true })
          .then((stream) => {
            const newTrack = stream.getAudioTracks()[0];
            if (newTrack) {
              const mediaStream = publisher.stream.getMediaStream();
              const oldTrack = mediaStream.getAudioTracks()[0];
              publisher.replaceTrack(newTrack); // ğŸ”„ OpenVidu í¼ë¸”ë¦¬ì…” íŠ¸ë™ êµì²´
              oldTrack?.stop(); // ê¸°ì¡´ íŠ¸ë™ ì •ë¦¬
            }
            publisher.publishAudio(true);
          })
          .catch((error) => console.error("ğŸš¨ ë§ˆì´í¬ ì ‘ê·¼ ì‹¤íŒ¨: ", error));
      } else {
        publisher.publishAudio(false);
        publisher.stream
          .getMediaStream()
          .getAudioTracks()
          .forEach((track) => track.stop());
      }
    }
  }, [micStatus[userId], publisher]);

  // mic-status ì‹ í˜¸ ìˆ˜ì‹ 
  const handleMicStatusSignal = (event: SignalEvent) => {
    if (!sessionRef.current) {
      console.warn(
        "âš ï¸ [handleMicStatusSignal] ì„¸ì…˜ ì •ë³´ê°€ ì—†ìŒ. ì„¸ì…˜ì„ ë‹¤ì‹œ ì´ˆê¸°í™”í•´ì•¼ í•©ë‹ˆë‹¤.",
      );
      return;
    }

    const currentSession = sessionRef.current;

    if (!currentSession.connection) {
      console.warn(
        "âš ï¸ [handleMicStatusSignal] ì„¸ì…˜ì€ ì¡´ì¬í•˜ì§€ë§Œ, ì—°ê²° ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤.",
      );
      return;
    }

    if (!event.data) {
      console.warn("âš ï¸ mic-status ì´ë²¤íŠ¸ì— ë°ì´í„°ê°€ ì—†ìŒ");
      return;
    }

    try {
      const parseData = JSON.parse(event.data);
      console.log(
        `ğŸ¤ [handleMicStatusSignal] userId: ${parseData.userId}, isMicOn: ${parseData.isMicOn}`,
      );

      if (
        typeof parseData.userId !== "number" ||
        typeof parseData.isMicOn !== "boolean"
      ) {
        console.warn("âš ï¸ ì˜ëª»ëœ mic-status ë°ì´í„° í˜•ì‹:", parseData);
        return;
      }

      setMicStatus(parseData.userId, parseData.isMicOn);
    } catch (error) {
      console.error("ğŸš¨ mic-status ë°ì´í„° íŒŒì‹± ì˜¤ë¥˜:", error);
    }
  };

  return null;
};
export default WebRTCManager;
