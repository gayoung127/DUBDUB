"use client";

import gsap from "gsap";
import { toast } from "sonner";
import { Draggable } from "gsap/Draggable";
import React, { useEffect, useRef, useState } from "react";

import useBlockStore from "@/app/_store/BlockStore";
import { useTimeStore } from "@/app/_store/TimeStore";
import { AudioFile, Block, PX_PER_SECOND, Track } from "@/app/_types/studio";

import AudioBlockModal from "./AudioBlockModal";
import { useStompStore } from "@/app/_store/StompStore";
import { useSessionIdStore } from "@/app/_store/SessionIdStore";

export interface AudioBlockProps extends Block {
  audioContext: AudioContext | null;
  audioBuffers: Map<string, AudioBuffer> | null;
  setTracks: React.Dispatch<React.SetStateAction<Track[]>>;
  timelineRef: React.RefObject<HTMLDivElement | null>;
  trackId: number | null;
  fileIdx: number | null;
}

gsap.registerPlugin(Draggable);

const AudioBlock = ({
  file,
  width,
  waveColor,
  blockColor,
  audioContext,
  audioBuffers,
  setTracks,
  timelineRef,
  trackId,
  fileIdx,
}: AudioBlockProps) => {
  const { time, isPlaying } = useTimeStore();
  const {
    selectedBlocks,
    setSelectedBlocks,
    setSelectedBlockObj,
    clearSelectedBlocks,
  } = useBlockStore();
  const { stompClientRef, isConnected } = useStompStore();
  const { sessionId } = useSessionIdStore();

  const canvasRef = useRef<HTMLCanvasElement | null>(null);
  const audioSourceRef = useRef<AudioBufferSourceNode | null>(null);
  const blockRef = useRef<HTMLDivElement | null>(null);

  const [zIndex, setZIndex] = useState<number>(1);
  const [localStartPoint, setLocalStartPoint] = useState<number>(
    (file.startPoint + file.trimStart) * PX_PER_SECOND,
  );

  // ‚úÖ ÏÑ†ÌÉùÎêú Î∏îÎ°ùÏù∏ÏßÄ ÌôïÏù∏ÌïòÎäî Ìï®Ïàò
  const isSelected = selectedBlocks.some((b) => b.id === file.id);

  // useEffect: Î∏îÎ°ù ÏÑ†ÌÉù Ïãú, Í∞ÄÏû• ÏúÑÎ°ú Ïò¨ÎùºÏò§Í≤å ÎëêÍ∏∞ (z-index = 200 ÏÑ§Ï†ï)
  useEffect(() => {
    if (isSelected) {
      setZIndex(200);
    } else {
      setZIndex(1);
    }
  }, [selectedBlocks]);

  // useEffect: ÌÉÄÏûÑÎùºÏù∏ ÎÇ¥ ÏãúÏûëÏ†ê ÏóÖÎç∞Ïù¥Ìä∏ (ÏûêÎ•¥Í∏∞ ÏãúÏûë Î∞òÏòÅÌïú Î∂ÄÎ∂Ñ Î∞òÏòÅ)
  useEffect(() => {
    setLocalStartPoint((file.startPoint + file.trimStart) * PX_PER_SECOND);
  }, [file.startPoint, file.trimStart]);

  // useEffect: Ïò§ÎîîÏò§ Î∏îÎ°ù ÎìúÎûòÍ∑∏
  useEffect(() => {
    if (!blockRef.current || !timelineRef.current) return;

    const blockElement = blockRef.current;
    const timelineElement = timelineRef.current as HTMLElement;

    const draggable = Draggable.create(blockElement, {
      type: "x",
      bounds: timelineElement,
      inertia: true,
      cursor: "url('/images/icons/cursor-grab.svg') 10 10, grab;",
      onPress: function () {
        setZIndex(200); // ÎìúÎûòÍ∑∏ ÏãúÏûëÌïòÎ©¥ z-index ÏµúÏÉÅÏúÑÎ°ú Î≥ÄÍ≤Ω
        gsap.set(blockElement, {
          zIndex: 200,
          cursor: "url('/images/icons/cursor-grabbing.svg') 10 10, grabbing", // ÎìúÎûòÍ∑∏ ÏãúÏûë Ïãú Ïª§ÏÑú Î≥ÄÍ≤Ω
        });
      },
      onDrag: function () {
        const newStartPoint = Math.max(0, Math.round(this.x * 100) / 100);
        setLocalStartPoint(newStartPoint);
        gsap.set(blockElement, { zIndex: 200, x: newStartPoint });
      },
      onDragEnd: function () {
        gsap.set(blockElement, { zIndex: 200 });
        const finalStartPoint = Math.max(
          0,
          Math.round((this.x / PX_PER_SECOND) * 100) / 100,
        );

        setTracks((prevTracks) =>
          prevTracks.map((track) => ({
            ...track,
            files: track.files.map((f) =>
              f.id === file.id
                ? { ...f, startPoint: finalStartPoint - f.trimStart }
                : f,
            ),
          })),
        );
      },
      onRelease: function () {
        gsap.set(blockElement, {
          zIndex: 200,
          cursor: "url('/images/icons/cursor-grab.svg') 10 10, grab", // ÎìúÎûòÍ∑∏ Ï¢ÖÎ£å ÌõÑ Îã§Ïãú grab
        });
      },
    });

    return () => {
      draggable[0].kill();
    };
  }, [setTracks, file.id, timelineRef]);

  // useEffect: Îã§Î•∏ ÏÇ¨ÎûåÏù¥ Î∏îÎ°ù ÎìúÎûòÍ∑∏ Ïãú, Ìï¥Îãπ Ï¢åÌëú ÎèôÍ∏∞Ìôî
  useEffect(() => {
    if (blockRef.current) {
      gsap.set(blockRef.current, {
        x: (file.startPoint + file.trimStart) * PX_PER_SECOND,
      });
    }
  }, [file.startPoint, file.trimStart]);

  // useEffect: Ïò§ÎîîÏò§ Ìä∏Îûô ÏãúÏûëÏ†ê Î∞òÏòÅ
  useEffect(() => {
    if (!audioContext) return;

    const startOffset = file.startPoint + file.trimStart;
    const endOffset =
      startOffset + (file.duration - file.trimEnd - file.trimStart);

    if (!isPlaying && audioSourceRef.current) {
      stopAudio();
    }

    if (
      isPlaying &&
      time >= startOffset &&
      time < endOffset &&
      !audioSourceRef.current
    ) {
      playAudio();
    } else if (time >= endOffset && audioSourceRef.current) {
      stopAudio();
    }
  }, [time, isPlaying, file.startPoint]);

  // useEffect: ÌååÏùº URL Î∞òÏòÅÏãú, ÌååÌòï ÏÉùÏÑ±
  useEffect(() => {
    if (!file.url) return;

    if (audioBuffers?.get(file.url)) {
      // üîπ Ïù¥ÎØ∏ `audioBuffers`Ïóê ÏûàÏúºÎ©¥ Î∞îÎ°ú ÏãúÍ∞ÅÌôî
      visualizeWaveform(audioBuffers.get(file.url)!);
    } else {
      // üîπ ÏóÜÏúºÎ©¥ fetch()Î°ú Î∞õÏïÑÏôÄÏÑú ÏãúÍ∞ÅÌôî
      fetchAudioBuffer(file.url).then((audioBuffer) => {
        if (audioBuffer) visualizeWaveform(audioBuffer);
      });
    }
  }, [audioBuffers, file.url]);

  const fetchAudioBuffer = async (url: string): Promise<AudioBuffer | null> => {
    if (!audioContext) return null;

    try {
      const response = await fetch(url);
      const arrayBuffer = await response.arrayBuffer();
      return await audioContext.decodeAudioData(arrayBuffer);
    } catch (error) {
      console.error("‚ùå Ïò§ÎîîÏò§ Î≤ÑÌçº Í∞ÄÏ†∏Ïò§Í∏∞ Ïã§Ìå®:", error);
      return null;
    }
  };

  // visualizeWaveForm() : ÌååÌòï ÏÉùÏÑ±
  const visualizeWaveform = (audioBuffer: AudioBuffer) => {
    const canvas = canvasRef.current;
    if (!canvas) return;

    const context = canvas.getContext("2d");
    if (!context) return;

    canvas.width = canvas.offsetWidth;
    canvas.height = canvas.offsetHeight;

    const waveform = audioBuffer.getChannelData(0);
    const sampleRate = audioBuffer.sampleRate;

    const startIndex = Math.floor(file.trimStart * sampleRate);
    const endIndex = Math.floor((file.duration - file.trimEnd) * sampleRate);

    const trimmedWaveform = waveform.slice(startIndex, endIndex);

    const step = Math.ceil(trimmedWaveform.length / canvas.width);
    const amp = canvas.height / 2;

    context.clearRect(0, 0, canvas.width, canvas.height);
    context.fillStyle = waveColor;

    for (let i = 0; i < canvas.width; i += 3) {
      const min = Math.min(...trimmedWaveform.slice(i * step, (i + 1) * step));
      const max = Math.max(...trimmedWaveform.slice(i * step, (i + 1) * step));

      context.fillRect(i, (1 + min) * amp, 2, Math.max(2, (max - min) * amp));
    }
  };

  const playAudio = async () => {
    if (!audioContext || audioSourceRef.current || !file.url) return;

    try {
      // üî• fetchÎ°ú Ïò§ÎîîÏò§ ÌååÏùº Î∂àÎü¨Ïò§Í∏∞
      const response = await fetch(file.url);
      const arrayBuffer = await response.arrayBuffer();
      const audioBuffer = await audioContext.decodeAudioData(arrayBuffer);

      const source = audioContext.createBufferSource();
      source.buffer = audioBuffer;

      const gainNode = audioContext.createGain();

      // ‚úÖ `volume`Ïù¥ Ïú†Ìö®Ìïú Í∞íÏù∏ÏßÄ ÌôïÏù∏ ÌõÑ Ï†ÅÏö©
      const volume = Number.isFinite(file.volume) ? file.volume : 1;
      gainNode.gain.value = file.isMuted ? 0 : volume;

      source.connect(gainNode);
      gainNode.connect(audioContext.destination);

      // ‚úÖ `speed`ÎèÑ Ïú†Ìö®Ìïú Í∞íÏù∏ÏßÄ ÌôïÏù∏ ÌõÑ Ï†ÅÏö©
      const playbackRate = Number.isFinite(file.speed) ? file.speed : 1;
      source.playbackRate.value = playbackRate;

      // ‚úÖ trimStart, trimEnd Í≤ÄÏ¶ù ÌõÑ Í∞í ÏÑ§Ï†ï
      const offset = Math.max(0, file.trimStart || 0);
      const duration = Math.max(
        0,
        (file.duration || 0) - offset - (file.trimEnd || 0),
      );

      source.start(audioContext.currentTime, offset, duration);

      audioSourceRef.current = source;

      source.onended = () => {
        audioSourceRef.current = null;
      };

      console.log("üéµ Ïò§ÎîîÏò§ Ïû¨ÏÉù ÏãúÏûë:", file.url);
    } catch (error) {
      console.error("‚ùå Ïò§ÎîîÏò§ Î°úÎìú Ïã§Ìå®:", error);
      toast.error("Ïò§ÎîîÏò§ ÌååÏùºÏùÑ Î∂àÎü¨Ïò§Îäî Îç∞ Ïã§Ìå®ÌñàÏäµÎãàÎã§.");
    }
  };

  // stopAudio(): Í∞úÎ≥Ñ Ïò§ÎîîÏò§ ÌååÏùº Ï¶âÏãú Ï†ïÏßÄ Ìï®Ïàò
  const stopAudio = () => {
    if (audioSourceRef.current) {
      audioSourceRef.current.stop();
      audioSourceRef.current.disconnect();
      audioSourceRef.current = null;
    }
  };

  // splitBlock(): Î∏îÎ°ù ÏûêÎ•¥Í∏∞ Ìï®Ïàò
  const splitBlock = () => {
    const blockStartX = localStartPoint; // Î∏îÎ°ùÏùò Ïã§Ï†ú ÏãúÏûë ÏúÑÏπò (px)
    const blockEndX = blockStartX + file.duration * PX_PER_SECOND; // Î∏îÎ°ù ÎÅù ÏúÑÏπò (px)
    const markerX = time * PX_PER_SECOND; // ÌòÑÏû¨ ÎßàÏª§ ÏúÑÏπò (px)

    if (markerX <= blockStartX || markerX >= blockEndX) {
      toast.warning("ÎßàÏª§Î•º Ïò§ÎîîÏò§ Î∏îÎ°ù ÏúÑÎ°ú Ïù¥ÎèôÌï¥Ï£ºÏÑ∏Ïöî!");
      return;
    }

    const cutTime = (markerX - blockStartX) / PX_PER_SECOND; // ÎßàÏª§ Í∏∞Ï§ÄÏúºÎ°ú Î∏îÎ°ùÏù¥ ÎÇòÎâòÎäî ÏãúÍ∞Ñ Í≥ÑÏÇ∞

    const newLeftBlock: Block = {
      file: {
        ...file,
        id: `${file.id}-left`,
        trimStart: file.trimStart, // Í∏∞Ï°¥ trimStart Ïú†ÏßÄ
        trimEnd: file.duration - cutTime - file.trimStart, // trimEnd Î≥ÄÍ≤Ω (ÎßàÏª§ Ïù¥ÌõÑ ÏûòÎùºÎÉÑ)
      },
      width: `${cutTime * PX_PER_SECOND}px`, // Î∏îÎ°ù ÌÅ¨Í∏∞ Ï°∞Ï†ï
      waveColor,
      blockColor,
    };

    const newRightBlock: Block = {
      file: {
        ...file,
        id: `${file.id}-right`,
        startPoint: file.startPoint, // Í∏∞Ï°¥ startPoint Ïú†ÏßÄ
        trimStart: file.trimStart + cutTime, // trimStart Î≥ÄÍ≤Ω (ÎßàÏª§ Ïù¥Ï†Ñ Î∂ÄÎ∂ÑÏùÑ ÏûòÎùºÎÇ¥Í∏∞)
        trimEnd: file.trimEnd, // Í∏∞Ï°¥ trimEnd Ïú†ÏßÄ
      },
      width: `${(file.duration - cutTime) * PX_PER_SECOND}px`, // Î∏îÎ°ù ÌÅ¨Í∏∞ Ï°∞Ï†ï
      waveColor,
      blockColor,
    };

    // üî• Í∏∞Ï°¥ Î∏îÎ°ùÏùÑ STOMP ÏÑúÎ≤ÑÏóêÏÑú ÏÇ≠Ï†ú (DELETE Ïï°ÏÖò)
    if (stompClientRef?.connected && sessionId) {
      const deleteAction = {
        trackId: trackId,
        action: "DELETE",
        file: {
          id: file.id,
        },
      };

      stompClientRef.publish({
        destination: `/app/studio/${sessionId}/track/files`,
        body: JSON.stringify(deleteAction),
      });

      console.log(
        "üóëÔ∏è useTrackSocket: [Ìä∏Îûô ÏÇ≠Ï†ú] ÏÑúÎ≤ÑÏóê DELETE Ïï°ÏÖò Ï†ÑÏÜ°:",
        deleteAction,
      );
    }

    // ‚úÖ Í∏∞Ï°¥ Î∏îÎ°ùÏùÑ ÏÇ≠Ï†úÌïòÍ≥† ÏÉàÎ°úÏö¥ Î∏îÎ°ù Ï∂îÍ∞Ä
    setTracks((prevTracks) =>
      prevTracks.map((track) => ({
        ...track,
        files: track.files.flatMap((f) =>
          f.id === file.id ? [newLeftBlock.file, newRightBlock.file] : [f],
        ),
      })),
    );

    // ‚úÖ ÏÑ†ÌÉùÎêú Î∏îÎ°ù Ï¥àÍ∏∞Ìôî (ÏÇ≠Ï†úÎêú Î∏îÎ°ùÏùÑ Ï∞∏Ï°∞ÌïòÎäî Î¨∏Ï†ú Ìï¥Í≤∞)
    clearSelectedBlocks();
    setSelectedBlockObj({
      applyToAll: false,
      selectedAudioFile: null,
      trackId: null,
      blockIndex: null,
    });

    toast.success("Î∏îÎ°ù ÏûêÎ•¥Í∏∞Í∞Ä ÏÑ±Í≥µÏ†ÅÏúºÎ°ú Ïù¥Î§ÑÏ°åÏäµÎãàÎã§!");
  };

  // deleteBlock(): Î∏îÎ°ù ÏÇ≠Ï†ú Ìï®Ïàò
  const deleteBlock = () => {
    setTracks((prevTracks) =>
      prevTracks.map((track) => ({
        ...track,
        files: track.files.filter((f) => f.id !== file.id),
      })),
    );

    clearSelectedBlocks();
    setSelectedBlockObj({
      applyToAll: false,
      selectedAudioFile: null,
      trackId: null,
      blockIndex: null,
    });

    if (stompClientRef?.connected && sessionId) {
      const deleteAction = {
        trackId: trackId,
        action: "DELETE",
        file: {
          id: file.id,
        },
      };

      stompClientRef.publish({
        destination: `/app/studio/${sessionId}/track/files`,
        body: JSON.stringify(deleteAction),
      });

      console.log(
        "üóëÔ∏è useTrackSocket: [Ìä∏Îûô ÏÇ≠Ï†ú] ÏÑúÎ≤ÑÏóê DELETE Ïï°ÏÖò Ï†ÑÏÜ°:",
        deleteAction,
      );
      toast.success("ÏÑ±Í≥µÏ†ÅÏúºÎ°ú Ïò§ÎîîÏò§ Î∏îÎ°ùÏùÑ ÏÇ≠Ï†úÌñàÏäµÎãàÎã§!");
    }
  };

  // useEffect: Ïò§ÎîîÏò§ Î∏îÎ°ù ÌÇ§Î≥¥Îìú Ïù¥Î≤§Ìä∏
  useEffect(() => {
    const handleKeyDown = (event: KeyboardEvent) => {
      // c : ÏûêÎ•¥Í∏∞ Í∏∞Îä•
      if (event.key.toLowerCase() === "c" && isSelected) {
        splitBlock();
      }

      // delete : Ïò§ÎîîÏò§ Î∏îÎ°ù ÏÇ≠Ï†ú Í∏∞Îä•
      if (event.key.toLowerCase() === "delete" && isSelected) {
        deleteBlock();
        console.log("‚úÖ Î∏îÎ°ùÏù¥ ÏÇ≠Ï†úÎêòÏóàÏäµÎãàÎã§!", file.id);
      }
    };
    window.addEventListener("keydown", handleKeyDown);
    return () => window.removeEventListener("keydown", handleKeyDown);
  }, [selectedBlocks]);

  // ‚úÖ Î∏îÎ°ù ÌÅ¥Î¶≠ Ïù¥Î≤§Ìä∏ Ìï∏Îì§Îü¨
  const handleBlockClick = () => {
    setSelectedBlocks((prevBlocks: AudioFile[]) => {
      let updatedBlocks;

      // ‚úÖ Ïù¥ÎØ∏ ÏÑ†ÌÉùÎêú Î∏îÎ°ùÏù¥Î©¥ Ï†úÍ±∞
      if (prevBlocks.some((b) => b.id === file.id)) {
        updatedBlocks = prevBlocks.filter((b) => b.id !== file.id);
      } else {
        // ‚úÖ ÏïÑÎãàÎùºÎ©¥ Ï∂îÍ∞Ä
        updatedBlocks = [...prevBlocks, file];
      }

      // üî• ÏÑ†ÌÉùÎêú Î∏îÎ°ùÎì§ ÏΩòÏÜîÏóê Ï∂úÎ†•
      console.log(
        "üü° ÌòÑÏû¨ ÏÑ†ÌÉùÎêú Î∏îÎ°ùÎì§:",
        updatedBlocks.map((b) => b.id),
      );

      return updatedBlocks;
    });

    setSelectedBlockObj({
      applyToAll: false,
      selectedAudioFile: file,
      trackId: trackId,
      blockIndex: fileIdx,
    });

    setZIndex(100);
  };

  // ‚úÖ ÏÑ†ÌÉùÎêú Î∏îÎ°ùÎì§ ÏΩòÏÜî Ï∂úÎ†• (Îß§Î≤à `selectedBlocks`Ïù¥ Î≥ÄÍ≤ΩÎê† Îïå)
  useEffect(() => {
    console.log(
      "‚úÖ ÏÑ†ÌÉùÎêú Î∏îÎ°ùÎì§ ÏóÖÎç∞Ïù¥Ìä∏:",
      selectedBlocks.map((b) => b.id),
    );
  }, [selectedBlocks]);

  return (
    <div
      ref={blockRef}
      className="draggable absolute flex h-full items-center justify-start"
      style={{
        width: width,
        transform: `translateX(${localStartPoint}px)`,
        backgroundColor: blockColor,
        borderRadius: `8px`,
        zIndex: zIndex,
      }}
      onClick={handleBlockClick}
    >
      <canvas
        ref={canvasRef}
        className={`h-10 w-full rounded-md border border-transparent hover:border-brand-300 ${isSelected ? "border-2 border-yellow-600" : ""}`} // ÏÑ†ÌÉù Ïãú ÏÉâÏÉÅ
        style={{
          backgroundColor: blockColor,
        }}
      ></canvas>
      {isSelected && (
        <div className="relative z-[999999] overflow-visible">
          <div className="bg-white shadow-md absolute -top-5 left-2 z-[999999] p-4">
            <AudioBlockModal
              handleCrop={splitBlock}
              handleDelete={deleteBlock}
            />
          </div>
        </div>
      )}
    </div>
  );
};

export default AudioBlock;
